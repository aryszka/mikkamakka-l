package next

type choiceDefinition struct {
	name     string
	commit   CommitType
	elements []string
}

type choiceParser struct {
	name     string
	commit   CommitType
	elements []parser
}

func newChoice(name string, ct CommitType, elements []string) *choiceDefinition {
	return &choiceDefinition{
		name:     name,
		commit:   ct,
		elements: elements,
	}
}

func (d *choiceDefinition) nodeName() string { return d.name }

func (d *choiceDefinition) parser(r *registry) (parser, error) {
	p, ok := r.parser(d.name)
	if ok {
		return p, nil
	}

	cp := &choiceParser{
		name:   d.name,
		commit: d.commit,
	}

	r.setParser(cp)

	var elements []parser
	for _, e := range d.elements {
		element, ok := r.parser(e)
		if ok {
			elements = append(elements, element)
			continue
		}

		elementDefinition, ok := r.definition(e)
		if !ok {
			return nil, parserNotFound(e)
		}

		element, err := elementDefinition.parser(r)
		if err != nil {
			return nil, err
		}

		elements = append(elements, element)
	}

	cp.elements = elements
	return cp, nil
}

func (d *choiceDefinition) commitType() CommitType {
	return d.commit
}

func (p *choiceParser) nodeName() string { return p.name }

func (p *choiceParser) parse(t Trace, c *context, excluded []string) {
	t = t.Extend(p.name)
	t.Out1("parsing choice", c.offset)

	if p.commit&Documentation != 0 {
		t.Out1("fail, doc")
		c.fail(c.offset)
		return
	}

	if stringsContain(excluded, p.name) {
		t.Out1("excluded")
		c.fail(c.offset)
		return
	}

	if m, ok := c.fromCache(p.name); ok {
		t.Out1("found in cache, match:", m)
		return
	}

	excluded = append(excluded, p.name)
	node := newNode(p.name, p.commit, c.offset, c.offset)
	var match bool

	for {
		elements := p.elements
		var foundMatch bool

		// TODO: this can be the entry point for a transformation that enables the
		// processing of massive amounts of autogenerated rules in parallel in a
		// continously, dynamically cached way. E.g. teach a machine that learns
		// everything from a public library.

		for len(elements) > 0 {
			elements[0].parse(t, c, excluded)
			elements = elements[1:]
			c.offset = node.from

			if !c.match || match && c.node.tokenLength() <= node.tokenLength() {
				continue
			}

			match = true
			foundMatch = true
			node.clear()
			node.append(c.node)
			c.cache.set(node.from, p.name, node)

			// TODO: a simple break here can force PEG-style "priority" choices
		}

		if !foundMatch {
			break
		}
	}

	if match {
		t.Out1("success")
		c.success(node)
		return
	}

	t.Out1("fail")
	c.cache.set(node.from, p.name, nil)
	c.fail(node.from)
}
